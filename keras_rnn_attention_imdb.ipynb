{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "keras_rnn_attention_imdb.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ztjfreedom/colab/blob/master/keras_rnn_attention_imdb.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I09I38xgXNhU",
        "colab_type": "text"
      },
      "source": [
        "In this tutorial, We build text classification models in Keras that use attention mechanism to provide insight into how classification decisions are being made.\n",
        "\n",
        "## Prepare Dataset\n",
        "Weâ€™ll use the IMDB dataset that contains the text of 50,000 movie reviews from the Internet Movie Database. The IMDB dataset comes packaged with Keras. It has already been preprocessed such that the sequences of words have been converted to sequences of integers, where each integer represents a specific word in a dictionary."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GImY1NB7XR6Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib inline\n",
        "import os\n",
        "import tensorflow as tf\n",
        "import keras.backend as K\n",
        "from keras_preprocessing import sequence\n",
        "from keras.layers import *\n",
        "from keras.models import *\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-K1Lx9F7qcs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = 10000\n",
        " \n",
        "pad_id = 0\n",
        "start_id = 1\n",
        "oov_id = 2\n",
        "index_offset = 2\n",
        " \n",
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.imdb.load_data(num_words=vocab_size, start_char=start_id,\n",
        "                                                                        oov_char=oov_id, index_from=index_offset)\n",
        " \n",
        "word2idx = tf.keras.datasets.imdb.get_word_index()\n",
        " \n",
        "print('Min index in word2idx:', min(word2idx.items(), key=lambda item: item[1]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJ7I2oatZmk7",
        "colab_type": "text"
      },
      "source": [
        "Keras provide function pad_sequences takes care padding sequences. We only have to give it the max_len argument which will determine the length of the output arrays. If sentences are shorter than this length, they will be padded and if they are longer, they will be trimmed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H51N3DMtXykh",
        "colab_type": "code",
        "outputId": "4bd21de3-07e6-464d-8a02-4a1b80785311",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "word2idx = {k: v + index_offset for k, v in word2idx.items()}\n",
        "idx2word = {v: k for k, v in word2idx.items()}\n",
        " \n",
        "idx2word[pad_id] = '<PAD>'\n",
        "idx2word[start_id] = '<START>'\n",
        "idx2word[oov_id] = '<OOV>'\n",
        " \n",
        "max_len = 80\n",
        "rnn_cell_size = 128\n",
        " \n",
        "x_train = sequence.pad_sequences(x_train,\n",
        "                                 maxlen=max_len,\n",
        "                                 truncating='post',\n",
        "                                 padding='post',\n",
        "                                 value=pad_id)\n",
        "x_test = sequence.pad_sequences(x_test, \n",
        "                                maxlen=max_len,\n",
        "                                truncating='post',\n",
        "                                padding='post',\n",
        "                                value=pad_id)\n",
        "\n",
        "print('Review at word2idx:')\n",
        "print('word the:', word2idx['the'])\n",
        "\n",
        "print('Review at idx2word:')\n",
        "print('idx 0:', idx2word[0])\n",
        "print('idx 1:', idx2word[1])\n",
        "print('idx 2:', idx2word[2])\n",
        "print('idx 3:', idx2word[3])"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Review at word2idx:\n",
            "word the: 3\n",
            "Review at idx2word:\n",
            "idx 0: <PAD>\n",
            "idx 1: <START>\n",
            "idx 2: <OOV>\n",
            "idx 3: the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jS7RZ5OS5rFu",
        "colab_type": "text"
      },
      "source": [
        "## Pre-trained GLoVe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSpQMy6Q58HD",
        "colab_type": "code",
        "outputId": "a8a087db-0cbe-4a01-f69c-4915c2db8cc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "%cd gdrive/My Drive/Colab Notebooks/dataset/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "/content/gdrive/My Drive/Colab Notebooks/dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9o4qiHh58El",
        "colab_type": "code",
        "outputId": "4eb5a905-707b-47f1-89e5-e5e93d6421d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# Parsing GLoVE word embedding files\n",
        "glove_dict = {}\n",
        "with open(os.path.join('glove', 'glove.6B.50d.txt')) as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        coefs = np.asarray(values[1:], dtype='float32')\n",
        "        glove_dict[word] = coefs\n",
        "\n",
        "\n",
        "print('Found %s word vectors.' % len(glove_dict))\n",
        "\n",
        "for key in glove_dict.keys():\n",
        "    print('Frist key:', key)\n",
        "    break"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n",
            "Frist key: the\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EtdUcTPR58CI",
        "colab_type": "code",
        "outputId": "5878c542-83ff-45e8-f903-b0f14158b92b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "# 0 is used for padding, so we set it to all zeros\n",
        "embedding_matrix = np.random.normal(loc=0.0, scale=1.0, size=(vocab_size, 50))\n",
        "embedding_matrix[0] = np.zeros(50)\n",
        "for word, i in word2idx.items():\n",
        "    if i < 10000:\n",
        "        embedding_vector = glove_dict.get(word)\n",
        "        if embedding_vector is not None:\n",
        "            embedding_matrix[i] = embedding_vector\n",
        "\n",
        "print('Embedding review:')\n",
        "print(embedding_matrix.shape)\n",
        "print(embedding_matrix[0])\n",
        "print(embedding_matrix[1])\n",
        "print(embedding_matrix[3])\n",
        "print(glove_dict['the'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Embedding review:\n",
            "(10000, 50)\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            " 0. 0.]\n",
            "[ 1.42576577 -1.74478284 -0.64736253  0.26380198 -0.46950615  0.04085707\n",
            " -1.00885976  1.45821201 -1.06941491 -1.02752209 -0.63001538 -1.55715559\n",
            " -0.58781136 -0.16534477 -0.22280624 -0.92582924  0.63208453  0.67441906\n",
            "  1.1971006   1.90387458 -1.94896777 -0.8279956   1.06974494 -0.55934359\n",
            "  1.18077087  0.17849756  1.36668251  0.14156975 -0.66128088  1.30115542\n",
            " -1.43224451  1.35921625 -0.66289783  0.28906809 -0.80765559 -0.1648786\n",
            " -0.18261234 -0.36393716  1.21956617  0.52869823  2.4136912  -0.45797747\n",
            "  0.11586065 -0.55238252  0.47984307  0.65838836 -0.23103201 -1.21848454\n",
            "  1.27952061 -0.39359994]\n",
            "[ 4.18000013e-01  2.49679998e-01 -4.12420005e-01  1.21699996e-01\n",
            "  3.45270008e-01 -4.44569997e-02 -4.96879995e-01 -1.78619996e-01\n",
            " -6.60229998e-04 -6.56599998e-01  2.78430015e-01 -1.47670001e-01\n",
            " -5.56770027e-01  1.46579996e-01 -9.50950012e-03  1.16579998e-02\n",
            "  1.02040000e-01 -1.27920002e-01 -8.44299972e-01 -1.21809997e-01\n",
            " -1.68009996e-02 -3.32789987e-01 -1.55200005e-01 -2.31309995e-01\n",
            " -1.91809997e-01 -1.88230002e+00 -7.67459989e-01  9.90509987e-02\n",
            " -4.21249986e-01 -1.95260003e-01  4.00710011e+00 -1.85939997e-01\n",
            " -5.22870004e-01 -3.16810012e-01  5.92130003e-04  7.44489999e-03\n",
            "  1.77780002e-01 -1.58969998e-01  1.20409997e-02 -5.42230010e-02\n",
            " -2.98709989e-01 -1.57490000e-01 -3.47579986e-01 -4.56370004e-02\n",
            " -4.42510009e-01  1.87849998e-01  2.78489990e-03 -1.84110001e-01\n",
            " -1.15139998e-01 -7.85809994e-01]\n",
            "[ 4.1800e-01  2.4968e-01 -4.1242e-01  1.2170e-01  3.4527e-01 -4.4457e-02\n",
            " -4.9688e-01 -1.7862e-01 -6.6023e-04 -6.5660e-01  2.7843e-01 -1.4767e-01\n",
            " -5.5677e-01  1.4658e-01 -9.5095e-03  1.1658e-02  1.0204e-01 -1.2792e-01\n",
            " -8.4430e-01 -1.2181e-01 -1.6801e-02 -3.3279e-01 -1.5520e-01 -2.3131e-01\n",
            " -1.9181e-01 -1.8823e+00 -7.6746e-01  9.9051e-02 -4.2125e-01 -1.9526e-01\n",
            "  4.0071e+00 -1.8594e-01 -5.2287e-01 -3.1681e-01  5.9213e-04  7.4449e-03\n",
            "  1.7778e-01 -1.5897e-01  1.2041e-02 -5.4223e-02 -2.9871e-01 -1.5749e-01\n",
            " -3.4758e-01 -4.5637e-02 -4.4251e-01  1.8785e-01  2.7849e-03 -1.8411e-01\n",
            " -1.1514e-01 -7.8581e-01]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ostm8QQsZqnE",
        "colab_type": "text"
      },
      "source": [
        "## Attention mechanism in Keras\n",
        "Referring to https://github.com/philipperemy/keras-attention-mechanism\n",
        "\n",
        "The following 2 code blocks are used for example\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XH7Xt3k_ZcnT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 32\n",
        "\n",
        "def build_model_dense():\n",
        "    inputs = Input(shape=(INPUT_DIM,))\n",
        "\n",
        "    # ATTENTION PART STARTS HERE\n",
        "    attention_probs = Dense(INPUT_DIM, activation='softmax', name='attention_vec')(inputs)\n",
        "    attention_mul = merge([inputs, attention_probs], output_shape=32, name='attention_mul', mode='mul')\n",
        "    # ATTENTION PART FINISHES HERE\n",
        "\n",
        "    attention_mul = Dense(64)(attention_mul)\n",
        "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1v4eyRmW5kPY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "INPUT_DIM = 2\n",
        "TIME_STEPS = 20\n",
        "# if True, the attention vector is shared across the input_dimensions where the attention is applied.\n",
        "SINGLE_ATTENTION_VECTOR = False\n",
        "\n",
        "def attention_3d_block(inputs):\n",
        "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
        "    input_dim = int(inputs.shape[2])\n",
        "    a = Permute((2, 1))(inputs)\n",
        "    a = Reshape((input_dim, TIME_STEPS))(a) # this line is not useful. It's just to know which dimension is what.\n",
        "    a = Dense(TIME_STEPS, activation='softmax')(a)\n",
        "    if SINGLE_ATTENTION_VECTOR:\n",
        "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
        "        a = RepeatVector(input_dim)(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "    output_attention_mul = Multiply(name='attention_mul')([inputs, a_probs])\n",
        "    return output_attention_mul\n",
        "\n",
        "\n",
        "def model_attention_applied_after_lstm():\n",
        "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
        "    lstm_units = 32\n",
        "    lstm_out = LSTM(lstm_units, return_sequences=True)(inputs)\n",
        "    attention_mul = attention_3d_block(lstm_out)\n",
        "    attention_mul = Flatten()(attention_mul)\n",
        "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model\n",
        "\n",
        "\n",
        "def model_attention_applied_before_lstm():\n",
        "    inputs = Input(shape=(TIME_STEPS, INPUT_DIM,))\n",
        "    attention_mul = attention_3d_block(inputs)\n",
        "    lstm_units = 32\n",
        "    attention_mul = LSTM(lstm_units, return_sequences=False)(attention_mul)\n",
        "    output = Dense(1, activation='sigmoid')(attention_mul)\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqjOx4VS5Lyq",
        "colab_type": "text"
      },
      "source": [
        "## Modeling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CCvZpcmc9JEL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def attention_3d_block(inputs, time_steps, single_attention_vector):\n",
        "    # inputs.shape = (batch_size, time_steps, input_dim)\n",
        "    input_dim = int(inputs.shape[2])\n",
        "    a = Permute((2, 1))(inputs)\n",
        "    a = Reshape((input_dim, time_steps))(a) # this line is not useful. It's just to know which dimension is what.\n",
        "    a = Dense(time_steps, activation='softmax')(a)\n",
        "    if single_attention_vector:\n",
        "        a = Lambda(lambda x: K.mean(x, axis=1), name='dim_reduction')(a)\n",
        "        a = RepeatVector(input_dim)(a)\n",
        "    a_probs = Permute((2, 1), name='attention_vec')(a)\n",
        "    output_attention_mul = Multiply(name='attention_mul')([inputs, a_probs])\n",
        "    return output_attention_mul"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPCMFDC6Hlgi",
        "colab_type": "code",
        "outputId": "671c944a-725b-4cb0-85c8-9315cd98a368",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# attention before LSTM\n",
        "inputs = Input(shape=[max_len], dtype='int32')\n",
        "embedded = Embedding(input_dim=vocab_size, output_dim=50, input_length=max_len)(inputs)\n",
        "attention_mul = attention_3d_block(embedded, max_len, False)  # attention here\n",
        "embedded = Dropout(rate=0.5)(embedded)\n",
        "activations = Bidirectional(CuDNNLSTM(128))(attention_mul)\n",
        "output = Dense(1, activation='sigmoid')(activations)\n",
        "model = Model(input=[inputs], output=output)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:7: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
            "  import sys\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NHq_L9UG30se",
        "colab_type": "code",
        "outputId": "40111784-850c-46cb-ac4f-b1d207f10c79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# attention after LSTM\n",
        "inputs = Input(shape=[max_len], dtype='int32')\n",
        "embedded = Embedding(input_dim=vocab_size, output_dim=50, input_length=max_len)(inputs)\n",
        "embedded = Dropout(rate=0.5)(embedded)\n",
        "activations = Bidirectional(CuDNNLSTM(128, return_sequences=True))(embedded)\n",
        "attention_mul = attention_3d_block(activations, max_len, False)  # attention here\n",
        "attention_mul = Flatten()(attention_mul)\n",
        "output = Dense(1, activation='sigmoid')(attention_mul)\n",
        "model = Model(input=[inputs], output=output)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ic2xThMq6vie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# freeze embeddings\n",
        "model.layers[1].set_weights([embedding_matrix])\n",
        "model.layers[1].trainable = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZSONxR730la",
        "colab_type": "code",
        "outputId": "62b09120-f179-4108-d9c8-b5c4d614f132",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        }
      },
      "source": [
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_3 (InputLayer)            (None, 80)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_3 (Embedding)         (None, 80, 50)       500000      input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout_3 (Dropout)             (None, 80, 50)       0           embedding_3[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "bidirectional_3 (Bidirectional) (None, 80, 256)      184320      dropout_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "permute_3 (Permute)             (None, 256, 80)      0           bidirectional_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "reshape_3 (Reshape)             (None, 256, 80)      0           permute_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 256, 80)      6480        reshape_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "attention_vec (Permute)         (None, 80, 256)      0           dense_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "attention_mul (Multiply)        (None, 80, 256)      0           bidirectional_3[0][0]            \n",
            "                                                                 attention_vec[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten_1 (Flatten)             (None, 20480)        0           attention_mul[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_6 (Dense)                 (None, 1)            20481       flatten_1[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 711,281\n",
            "Trainable params: 211,281\n",
            "Non-trainable params: 500,000\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AkalDw3q30ek",
        "colab_type": "code",
        "outputId": "4890a667-e23a-497f-f9bc-54b67cb49dcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "SVG(model_to_dot(model, show_shapes=True).create(prog='dot', format='svg'))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg height=\"885pt\" viewBox=\"0.00 0.00 548.00 885.00\" width=\"548pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 881)\">\n<title>G</title>\n<polygon fill=\"#ffffff\" points=\"-4,4 -4,-881 544,-881 544,4 -4,4\" stroke=\"transparent\"/>\n<!-- 140463222781768 -->\n<g class=\"node\" id=\"node1\">\n<title>140463222781768</title>\n<polygon fill=\"none\" points=\"134.5,-830.5 134.5,-876.5 405.5,-876.5 405.5,-830.5 134.5,-830.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"201\" y=\"-849.8\">input_3: InputLayer</text>\n<polyline fill=\"none\" points=\"267.5,-830.5 267.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-861.3\">input:</text>\n<polyline fill=\"none\" points=\"267.5,-853.5 325.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"296.5\" y=\"-838.3\">output:</text>\n<polyline fill=\"none\" points=\"325.5,-830.5 325.5,-876.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-861.3\">(None, 80)</text>\n<polyline fill=\"none\" points=\"325.5,-853.5 405.5,-853.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"365.5\" y=\"-838.3\">(None, 80)</text>\n</g>\n<!-- 140463222783448 -->\n<g class=\"node\" id=\"node2\">\n<title>140463222783448</title>\n<polygon fill=\"none\" points=\"104.5,-747.5 104.5,-793.5 435.5,-793.5 435.5,-747.5 104.5,-747.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-766.8\">embedding_3: Embedding</text>\n<polyline fill=\"none\" points=\"275.5,-747.5 275.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-778.3\">input:</text>\n<polyline fill=\"none\" points=\"275.5,-770.5 333.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"304.5\" y=\"-755.3\">output:</text>\n<polyline fill=\"none\" points=\"333.5,-747.5 333.5,-793.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384.5\" y=\"-778.3\">(None, 80)</text>\n<polyline fill=\"none\" points=\"333.5,-770.5 435.5,-770.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"384.5\" y=\"-755.3\">(None, 80, 50)</text>\n</g>\n<!-- 140463222781768&#45;&gt;140463222783448 -->\n<g class=\"edge\" id=\"edge1\">\n<title>140463222781768-&gt;140463222783448</title>\n<path d=\"M270,-830.3799C270,-822.1745 270,-812.7679 270,-803.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"273.5001,-803.784 270,-793.784 266.5001,-803.784 273.5001,-803.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223818448 -->\n<g class=\"node\" id=\"node3\">\n<title>140463223818448</title>\n<polygon fill=\"none\" points=\"123,-664.5 123,-710.5 417,-710.5 417,-664.5 123,-664.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"190\" y=\"-683.8\">dropout_3: Dropout</text>\n<polyline fill=\"none\" points=\"257,-664.5 257,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-695.3\">input:</text>\n<polyline fill=\"none\" points=\"257,-687.5 315,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"286\" y=\"-672.3\">output:</text>\n<polyline fill=\"none\" points=\"315,-664.5 315,-710.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-695.3\">(None, 80, 50)</text>\n<polyline fill=\"none\" points=\"315,-687.5 417,-687.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"366\" y=\"-672.3\">(None, 80, 50)</text>\n</g>\n<!-- 140463222783448&#45;&gt;140463223818448 -->\n<g class=\"edge\" id=\"edge2\">\n<title>140463222783448-&gt;140463223818448</title>\n<path d=\"M270,-747.3799C270,-739.1745 270,-729.7679 270,-720.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"273.5001,-720.784 270,-710.784 266.5001,-720.784 273.5001,-720.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140463226531008 -->\n<g class=\"node\" id=\"node4\">\n<title>140463226531008</title>\n<polygon fill=\"none\" points=\"0,-581.5 0,-627.5 540,-627.5 540,-581.5 0,-581.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"186\" y=\"-600.8\">bidirectional_3(cu_dnnlstm_3): Bidirectional(CuDNNLSTM)</text>\n<polyline fill=\"none\" points=\"372,-581.5 372,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-612.3\">input:</text>\n<polyline fill=\"none\" points=\"372,-604.5 430,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"401\" y=\"-589.3\">output:</text>\n<polyline fill=\"none\" points=\"430,-581.5 430,-627.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-612.3\">(None, 80, 50)</text>\n<polyline fill=\"none\" points=\"430,-604.5 540,-604.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"485\" y=\"-589.3\">(None, 80, 256)</text>\n</g>\n<!-- 140463223818448&#45;&gt;140463226531008 -->\n<g class=\"edge\" id=\"edge3\">\n<title>140463223818448-&gt;140463226531008</title>\n<path d=\"M270,-664.3799C270,-656.1745 270,-646.7679 270,-637.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"273.5001,-637.784 270,-627.784 266.5001,-637.784 273.5001,-637.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140463227865688 -->\n<g class=\"node\" id=\"node5\">\n<title>140463227865688</title>\n<polygon fill=\"none\" points=\"30.5,-498.5 30.5,-544.5 331.5,-544.5 331.5,-498.5 30.5,-498.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"97\" y=\"-517.8\">permute_3: Permute</text>\n<polyline fill=\"none\" points=\"163.5,-498.5 163.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-529.3\">input:</text>\n<polyline fill=\"none\" points=\"163.5,-521.5 221.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"192.5\" y=\"-506.3\">output:</text>\n<polyline fill=\"none\" points=\"221.5,-498.5 221.5,-544.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.5\" y=\"-529.3\">(None, 80, 256)</text>\n<polyline fill=\"none\" points=\"221.5,-521.5 331.5,-521.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"276.5\" y=\"-506.3\">(None, 256, 80)</text>\n</g>\n<!-- 140463226531008&#45;&gt;140463227865688 -->\n<g class=\"edge\" id=\"edge4\">\n<title>140463226531008-&gt;140463227865688</title>\n<path d=\"M245.2085,-581.3799C235.3581,-572.1935 223.893,-561.5013 213.3994,-551.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"215.6676,-549.0446 205.9672,-544.784 210.8934,-554.1639 215.6676,-549.0446\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223364016 -->\n<g class=\"node\" id=\"node9\">\n<title>140463223364016</title>\n<polygon fill=\"none\" points=\"52.5,-166.5 52.5,-212.5 483.5,-212.5 483.5,-166.5 52.5,-166.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"129.5\" y=\"-185.8\">attention_mul: Multiply</text>\n<polyline fill=\"none\" points=\"206.5,-166.5 206.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-197.3\">input:</text>\n<polyline fill=\"none\" points=\"206.5,-189.5 264.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"235.5\" y=\"-174.3\">output:</text>\n<polyline fill=\"none\" points=\"264.5,-166.5 264.5,-212.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"374\" y=\"-197.3\">[(None, 80, 256), (None, 80, 256)]</text>\n<polyline fill=\"none\" points=\"264.5,-189.5 483.5,-189.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"374\" y=\"-174.3\">(None, 80, 256)</text>\n</g>\n<!-- 140463226531008&#45;&gt;140463223364016 -->\n<g class=\"edge\" id=\"edge8\">\n<title>140463226531008-&gt;140463223364016</title>\n<path d=\"M306.2165,-581.3296C318.7329,-571.5699 331.688,-559.1703 340,-545 364.4099,-503.3861 361,-486.7447 361,-438.5 361,-438.5 361,-438.5 361,-355.5 361,-307.4193 366.5163,-290.3607 342,-249 335.2347,-237.5865 325.409,-227.4685 315.1159,-218.9596\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"317.2313,-216.1707 307.1965,-212.7716 312.9213,-221.6866 317.2313,-216.1707\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223240744 -->\n<g class=\"node\" id=\"node6\">\n<title>140463223240744</title>\n<polygon fill=\"none\" points=\"30,-415.5 30,-461.5 328,-461.5 328,-415.5 30,-415.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"95\" y=\"-434.8\">reshape_3: Reshape</text>\n<polyline fill=\"none\" points=\"160,-415.5 160,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189\" y=\"-446.3\">input:</text>\n<polyline fill=\"none\" points=\"160,-438.5 218,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"189\" y=\"-423.3\">output:</text>\n<polyline fill=\"none\" points=\"218,-415.5 218,-461.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-446.3\">(None, 256, 80)</text>\n<polyline fill=\"none\" points=\"218,-438.5 328,-438.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"273\" y=\"-423.3\">(None, 256, 80)</text>\n</g>\n<!-- 140463227865688&#45;&gt;140463223240744 -->\n<g class=\"edge\" id=\"edge5\">\n<title>140463227865688-&gt;140463223240744</title>\n<path d=\"M180.4429,-498.3799C180.2452,-490.1745 180.0185,-480.7679 179.8043,-471.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"183.301,-471.6968 179.5611,-461.784 176.3031,-471.8655 183.301,-471.6968\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223240912 -->\n<g class=\"node\" id=\"node7\">\n<title>140463223240912</title>\n<polygon fill=\"none\" points=\"38.5,-332.5 38.5,-378.5 313.5,-378.5 313.5,-332.5 38.5,-332.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"92\" y=\"-351.8\">dense_5: Dense</text>\n<polyline fill=\"none\" points=\"145.5,-332.5 145.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-363.3\">input:</text>\n<polyline fill=\"none\" points=\"145.5,-355.5 203.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"174.5\" y=\"-340.3\">output:</text>\n<polyline fill=\"none\" points=\"203.5,-332.5 203.5,-378.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.5\" y=\"-363.3\">(None, 256, 80)</text>\n<polyline fill=\"none\" points=\"203.5,-355.5 313.5,-355.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"258.5\" y=\"-340.3\">(None, 256, 80)</text>\n</g>\n<!-- 140463223240744&#45;&gt;140463223240912 -->\n<g class=\"edge\" id=\"edge6\">\n<title>140463223240744-&gt;140463223240912</title>\n<path d=\"M178.1643,-415.3799C177.8678,-407.1745 177.5278,-397.7679 177.2065,-388.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"180.7006,-388.651 176.8416,-378.784 173.7052,-388.9039 180.7006,-388.651\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223365136 -->\n<g class=\"node\" id=\"node8\">\n<title>140463223365136</title>\n<polygon fill=\"none\" points=\"17,-249.5 17,-295.5 333,-295.5 333,-249.5 17,-249.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"91\" y=\"-268.8\">attention_vec: Permute</text>\n<polyline fill=\"none\" points=\"165,-249.5 165,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-280.3\">input:</text>\n<polyline fill=\"none\" points=\"165,-272.5 223,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"194\" y=\"-257.3\">output:</text>\n<polyline fill=\"none\" points=\"223,-249.5 223,-295.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278\" y=\"-280.3\">(None, 256, 80)</text>\n<polyline fill=\"none\" points=\"223,-272.5 333,-272.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"278\" y=\"-257.3\">(None, 80, 256)</text>\n</g>\n<!-- 140463223240912&#45;&gt;140463223365136 -->\n<g class=\"edge\" id=\"edge7\">\n<title>140463223240912-&gt;140463223365136</title>\n<path d=\"M175.7214,-332.3799C175.6226,-324.1745 175.5093,-314.7679 175.4022,-305.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"178.9008,-305.7411 175.2805,-295.784 171.9014,-305.8255 178.9008,-305.7411\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223365136&#45;&gt;140463223364016 -->\n<g class=\"edge\" id=\"edge9\">\n<title>140463223365136-&gt;140463223364016</title>\n<path d=\"M200.9057,-249.3799C211.1989,-240.1935 223.1792,-229.5013 234.1444,-219.7152\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"236.7804,-222.0539 241.9107,-212.784 232.1194,-216.8313 236.7804,-222.0539\" stroke=\"#000000\"/>\n</g>\n<!-- 140463227865800 -->\n<g class=\"node\" id=\"node10\">\n<title>140463227865800</title>\n<polygon fill=\"none\" points=\"127.5,-83.5 127.5,-129.5 408.5,-129.5 408.5,-83.5 127.5,-83.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"184\" y=\"-102.8\">flatten_1: Flatten</text>\n<polyline fill=\"none\" points=\"240.5,-83.5 240.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-114.3\">input:</text>\n<polyline fill=\"none\" points=\"240.5,-106.5 298.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"269.5\" y=\"-91.3\">output:</text>\n<polyline fill=\"none\" points=\"298.5,-83.5 298.5,-129.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-114.3\">(None, 80, 256)</text>\n<polyline fill=\"none\" points=\"298.5,-106.5 408.5,-106.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"353.5\" y=\"-91.3\">(None, 20480)</text>\n</g>\n<!-- 140463223364016&#45;&gt;140463227865800 -->\n<g class=\"edge\" id=\"edge10\">\n<title>140463223364016-&gt;140463227865800</title>\n<path d=\"M268,-166.3799C268,-158.1745 268,-148.7679 268,-139.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.5001,-139.784 268,-129.784 264.5001,-139.784 271.5001,-139.784\" stroke=\"#000000\"/>\n</g>\n<!-- 140463223365192 -->\n<g class=\"node\" id=\"node11\">\n<title>140463223365192</title>\n<polygon fill=\"none\" points=\"134.5,-.5 134.5,-46.5 401.5,-46.5 401.5,-.5 134.5,-.5\" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"188\" y=\"-19.8\">dense_6: Dense</text>\n<polyline fill=\"none\" points=\"241.5,-.5 241.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-31.3\">input:</text>\n<polyline fill=\"none\" points=\"241.5,-23.5 299.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"270.5\" y=\"-8.3\">output:</text>\n<polyline fill=\"none\" points=\"299.5,-.5 299.5,-46.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-31.3\">(None, 20480)</text>\n<polyline fill=\"none\" points=\"299.5,-23.5 401.5,-23.5 \" stroke=\"#000000\"/>\n<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"350.5\" y=\"-8.3\">(None, 1)</text>\n</g>\n<!-- 140463227865800&#45;&gt;140463223365192 -->\n<g class=\"edge\" id=\"edge11\">\n<title>140463227865800-&gt;140463223365192</title>\n<path d=\"M268,-83.3799C268,-75.1745 268,-65.7679 268,-56.8786\" fill=\"none\" stroke=\"#000000\"/>\n<polygon fill=\"#000000\" points=\"271.5001,-56.784 268,-46.784 264.5001,-56.784 271.5001,-56.784\" stroke=\"#000000\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bWNv-7H7FK3",
        "colab_type": "text"
      },
      "source": [
        "## 4.Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFaDeCkQ5j8I",
        "colab_type": "code",
        "outputId": "cff19087-b1a8-498f-99ee-13bd8c07c582",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 748
        }
      },
      "source": [
        "%%time\n",
        "epochs = 20\n",
        "validation_split = 0.2\n",
        "\n",
        "history = model.fit(x_train, y_train, batch_size=128,\n",
        "          epochs=epochs, \n",
        "          validation_split=validation_split)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 20000 samples, validate on 5000 samples\n",
            "Epoch 1/20\n",
            "20000/20000 [==============================] - 4s 212us/step - loss: 0.6445 - acc: 0.6235 - val_loss: 0.6874 - val_acc: 0.6314\n",
            "Epoch 2/20\n",
            "20000/20000 [==============================] - 3s 168us/step - loss: 0.5985 - acc: 0.6811 - val_loss: 0.5751 - val_acc: 0.6944\n",
            "Epoch 3/20\n",
            "20000/20000 [==============================] - 3s 169us/step - loss: 0.5756 - acc: 0.6996 - val_loss: 0.5373 - val_acc: 0.7352\n",
            "Epoch 4/20\n",
            "20000/20000 [==============================] - 3s 169us/step - loss: 0.5582 - acc: 0.7111 - val_loss: 0.5529 - val_acc: 0.7110\n",
            "Epoch 5/20\n",
            "20000/20000 [==============================] - 3s 170us/step - loss: 0.5456 - acc: 0.7210 - val_loss: 0.4965 - val_acc: 0.7600\n",
            "Epoch 6/20\n",
            "20000/20000 [==============================] - 3s 170us/step - loss: 0.5345 - acc: 0.7294 - val_loss: 0.5146 - val_acc: 0.7346\n",
            "Epoch 7/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.5259 - acc: 0.7323 - val_loss: 0.4784 - val_acc: 0.7724\n",
            "Epoch 8/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.5178 - acc: 0.7396 - val_loss: 0.4828 - val_acc: 0.7634\n",
            "Epoch 9/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.5073 - acc: 0.7475 - val_loss: 0.4734 - val_acc: 0.7724\n",
            "Epoch 10/20\n",
            "20000/20000 [==============================] - 3s 172us/step - loss: 0.5026 - acc: 0.7514 - val_loss: 0.4962 - val_acc: 0.7570\n",
            "Epoch 11/20\n",
            "20000/20000 [==============================] - 3s 172us/step - loss: 0.4955 - acc: 0.7521 - val_loss: 0.4722 - val_acc: 0.7724\n",
            "Epoch 12/20\n",
            "20000/20000 [==============================] - 3s 172us/step - loss: 0.4891 - acc: 0.7560 - val_loss: 0.4727 - val_acc: 0.7754\n",
            "Epoch 13/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.4826 - acc: 0.7613 - val_loss: 0.4681 - val_acc: 0.7836\n",
            "Epoch 14/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.4755 - acc: 0.7666 - val_loss: 0.4762 - val_acc: 0.7748\n",
            "Epoch 15/20\n",
            "20000/20000 [==============================] - 3s 172us/step - loss: 0.4732 - acc: 0.7685 - val_loss: 0.4576 - val_acc: 0.7880\n",
            "Epoch 16/20\n",
            "20000/20000 [==============================] - 3s 173us/step - loss: 0.4655 - acc: 0.7739 - val_loss: 0.4722 - val_acc: 0.7782\n",
            "Epoch 17/20\n",
            "20000/20000 [==============================] - 3s 172us/step - loss: 0.4620 - acc: 0.7747 - val_loss: 0.4644 - val_acc: 0.7776\n",
            "Epoch 18/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.4552 - acc: 0.7814 - val_loss: 0.4550 - val_acc: 0.7852\n",
            "Epoch 19/20\n",
            "20000/20000 [==============================] - 3s 170us/step - loss: 0.4493 - acc: 0.7809 - val_loss: 0.4585 - val_acc: 0.7884\n",
            "Epoch 20/20\n",
            "20000/20000 [==============================] - 3s 171us/step - loss: 0.4412 - acc: 0.7905 - val_loss: 0.4605 - val_acc: 0.7844\n",
            "CPU times: user 1min, sys: 6.97 s, total: 1min 7s\n",
            "Wall time: 1min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KCsN078C5jw9",
        "colab_type": "code",
        "outputId": "1be729be-e1d1-4866-ea70-d7319bf77c9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "scores = model.evaluate(x_test, y_test, verbose=2)\n",
        "print(\"%s: %.2f%%\" % (model.metrics_names[1], scores[1]*100))"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "acc: 78.15%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BuxJEWWt50j-",
        "colab_type": "text"
      },
      "source": [
        "## Attention visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_SR_771BVclq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_activations(model, inputs, layer_name=None):\n",
        "    # Documentation is available online on Github at the address below.\n",
        "    # From: https://github.com/philipperemy/keras-visualize-activations\n",
        "    print('----- activations -----')\n",
        "    activations = []\n",
        "    if layer_name is None:\n",
        "        layers = [layer.output for layer in model.layers]\n",
        "    else:\n",
        "        layers = [layer.output for layer in model.layers if layer.name == layer_name]  # all layer outputs\n",
        "    \n",
        "    funcs = [K.function([model.input, K.learning_phase()], [layer]) for layer in layers]  # evaluation functions\n",
        "    \n",
        "    layer_outputs = [func([inputs, 1]) for func in funcs]\n",
        "    \n",
        "    print(len(layer_outputs), len(layer_outputs[0]), layer_outputs[0][0].shape)\n",
        "    \n",
        "    return layer_outputs[0][0][0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_5YkXnkaVI3",
        "colab_type": "code",
        "outputId": "01a0ca5f-e846-4ea9-dc79-12e4395dfc7d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 340
        }
      },
      "source": [
        "sample = x_train[1]\n",
        "label = y_train[1]\n",
        "\n",
        "inputs = np.expand_dims(sample, axis=0)\n",
        "\n",
        "print('inputs data shape:', inputs.shape)\n",
        "\n",
        "activations = get_activations(model, inputs, layer_name='attention_vec')\n",
        "\n",
        "print(activations.shape)\n",
        "\n",
        "attention_vector = np.mean(activations, axis=1).squeeze()\n",
        "print('attention:')\n",
        "print(attention_vector)\n",
        "\n",
        "assert (np.sum(attention_vector) - 1.0) < 1e-5"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "inputs data shape: (1, 80)\n",
            "----- activations -----\n",
            "1 1 (1, 80, 256)\n",
            "(80, 256)\n",
            "attention:\n",
            "[0.00530922 0.01043579 0.00995418 0.00618045 0.00914546 0.01151391\n",
            " 0.00694041 0.01258886 0.01803346 0.01091918 0.0363     0.00979462\n",
            " 0.00846224 0.04192033 0.01101389 0.04685474 0.00841259 0.00752609\n",
            " 0.01988479 0.00586914 0.00683325 0.00747261 0.01853474 0.00722614\n",
            " 0.00604562 0.00711644 0.0058468  0.00753283 0.01179648 0.01150804\n",
            " 0.00824825 0.00841381 0.00866597 0.00771399 0.0076501  0.00643135\n",
            " 0.00533645 0.0098714  0.01319305 0.00780491 0.03347264 0.00708629\n",
            " 0.01127074 0.00549441 0.00851036 0.00654391 0.00986857 0.00806192\n",
            " 0.00624472 0.03274516 0.02570172 0.08882745 0.02267882 0.00595991\n",
            " 0.00948961 0.01834263 0.01060998 0.00587359 0.00685671 0.00639419\n",
            " 0.00674211 0.00714854 0.02199705 0.00728312 0.0103486  0.01574499\n",
            " 0.008606   0.01583651 0.00678484 0.00785065 0.00932697 0.00629636\n",
            " 0.0085499  0.01049377 0.00782604 0.00776382 0.00700607 0.01111082\n",
            " 0.01057423 0.01237469]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FlxPqDI8hcsb",
        "colab_type": "code",
        "outputId": "ef338ed2-ba7e-4c05-efc4-fa5544a96233",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 614
        }
      },
      "source": [
        "pd.DataFrame(attention_vector, columns=['attention (%)']).plot(kind='bar', title='Attention Mechanism as a function of input dimensions.', figsize=(20, 10))\n",
        "plt.show()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAABJIAAAJVCAYAAACF0N8pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8v8AZyC11AHObLgAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BvNawSQfhcqR",
        "colab_type": "code",
        "outputId": "0cc7562f-814f-45c2-abe1-406c2fcbf3e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "words = [(i, idx2word[index]) for i, index in enumerate(sample)]\n",
        "print(words)\n",
        "print(label)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(0, '<START>'), (1, 'big'), (2, 'hair'), (3, 'big'), (4, 'boobs'), (5, 'bad'), (6, 'music'), (7, 'and'), (8, 'a'), (9, 'giant'), (10, 'safety'), (11, 'pin'), (12, 'these'), (13, 'are'), (14, 'the'), (15, 'words'), (16, 'to'), (17, 'best'), (18, 'describe'), (19, 'this'), (20, 'terrible'), (21, 'movie'), (22, 'i'), (23, 'love'), (24, 'cheesy'), (25, 'horror'), (26, 'movies'), (27, 'and'), (28, \"i've\"), (29, 'seen'), (30, 'hundreds'), (31, 'but'), (32, 'this'), (33, 'had'), (34, 'got'), (35, 'to'), (36, 'be'), (37, 'on'), (38, 'of'), (39, 'the'), (40, 'worst'), (41, 'ever'), (42, 'made'), (43, 'the'), (44, 'plot'), (45, 'is'), (46, 'paper'), (47, 'thin'), (48, 'and'), (49, 'ridiculous'), (50, 'the'), (51, 'acting'), (52, 'is'), (53, 'an'), (54, 'abomination'), (55, 'the'), (56, 'script'), (57, 'is'), (58, 'completely'), (59, 'laughable'), (60, 'the'), (61, 'best'), (62, 'is'), (63, 'the'), (64, 'end'), (65, 'showdown'), (66, 'with'), (67, 'the'), (68, 'cop'), (69, 'and'), (70, 'how'), (71, 'he'), (72, 'worked'), (73, 'out'), (74, 'who'), (75, 'the'), (76, 'killer'), (77, 'is'), (78, \"it's\"), (79, 'just')]\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}